# ğŸš€ æ‰§è¡Œæ¸…å•

## ç¬¬ä¸€æ­¥ï¼šéªŒè¯ç³»ç»Ÿå®Œæ•´æ€§

### 1.1 æ£€æŸ¥æ–‡ä»¶

```bash
cd /Users/bytedance/Desktop/paper_agent/dataset_miner

# æ ¸å¿ƒAgentæ–‡ä»¶
ls -lh agent_*.py memory_system.py reflection_engine.py tool_manager.py

# åº”è¯¥çœ‹åˆ°:
# agent_core.py (8.1K)
# agent_controller.py (17K)
# memory_system.py (11K)
# reflection_engine.py (15K)
# tool_manager.py (14K)
```

### 1.2 æ£€æŸ¥ä¾èµ–

```bash
# æ£€æŸ¥Pythonç‰ˆæœ¬ï¼ˆéœ€è¦3.8+ï¼‰
python3 --version

# æ£€æŸ¥å¿…è¦çš„åŒ…
python3 -c "import openai, fitz, requests, pandas; print('ä¾èµ–OK')"

# å¦‚æœç¼ºå°‘åŒ…ï¼š
pip3 install openai pymupdf requests pandas matplotlib beautifulsoup4
```

---

## ç¬¬äºŒæ­¥ï¼šå¿«é€Ÿæµ‹è¯•ï¼ˆ5åˆ†é’Ÿï¼‰

### 2.1 æµ‹è¯•åŸå§‹Workflowï¼ˆå¯¹ç…§ç»„ï¼‰

```bash
# å…ˆå¤‡ä»½åŸæœ‰é…ç½®
cp main_neurips.py main_neurips.py.backup

# ç¼–è¾‘ main_neurips.pyï¼Œåœ¨ run() æ–¹æ³•ä¸­æ·»åŠ  max_papers å‚æ•°æ”¯æŒ
# æˆ–è€…ç›´æ¥è¿è¡Œï¼ˆä¼šå¤„ç†æ‰€æœ‰è®ºæ–‡ï¼‰

# æµ‹è¯•ï¼šåªå¤„ç†å°‘é‡è®ºæ–‡
python3 -c "
from main_neurips import NeurIPSDatasetMiner
miner = NeurIPSDatasetMiner(output_file='outputs/test_workflow.jsonl')
# æ³¨æ„ï¼šå¯èƒ½éœ€è¦ä¿®æ”¹ run() æ–¹æ³•æ”¯æŒ max_papers
"
```

### 2.2 æµ‹è¯•Agentç³»ç»Ÿ

```bash
# æµ‹è¯•ï¼šå¤„ç†3ç¯‡è®ºæ–‡
python3 main_agent.py

# é¢„æœŸè¾“å‡º:
# - outputs/dataset_agent_results.jsonl
# - dataset_miner_agent.log
# - memory/long_term_memory.jsonl

# æŸ¥çœ‹æ—¥å¿—ä¸­çš„å†³ç­–è¿‡ç¨‹
tail -20 dataset_miner_agent.log
```

### 2.3 éªŒè¯è¾“å‡º

```bash
# æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ç»“æœæ–‡ä»¶
ls -lh outputs/dataset_agent_results.jsonl

# æŸ¥çœ‹æå–çš„æ•°æ®é›†æ•°é‡
wc -l outputs/dataset_agent_results.jsonl

# æŸ¥çœ‹ç¬¬ä¸€ä¸ªç»“æœ
head -1 outputs/dataset_agent_results.jsonl | python3 -m json.tool
```

---

## ç¬¬ä¸‰æ­¥ï¼šæŸ¥çœ‹Agentå†³ç­–è¿‡ç¨‹

### 3.1 å®æ—¶ç›‘æ§

```bash
# ç»ˆç«¯1ï¼šè¿è¡ŒAgent
python3 main_agent.py

# ç»ˆç«¯2ï¼šå®æ—¶æŸ¥çœ‹å†³ç­–
tail -f dataset_miner_agent.log | grep -E "\[è§‚å¯Ÿ\]|\[æ¨ç†\]|\[åŠ¨ä½œ\]|\[åæ€\]"
```

### 3.2 æŸ¥çœ‹åæ€è¯¦æƒ…

```bash
# è¿‡æ»¤åæ€æ—¥å¿—
grep "\[åæ€\]" dataset_miner_agent.log

# åº”è¯¥çœ‹åˆ°ç±»ä¼¼:
# [åæ€] è´¨é‡=0.85, è¿›åº¦=0.50
# [æ´å¯Ÿ] æˆåŠŸæå–äº†3ä¸ªæ•°æ®é›†
```

### 3.3 æŸ¥çœ‹è®°å¿†ç»Ÿè®¡

```bash
# æŸ¥çœ‹æ—¥å¿—æœ«å°¾çš„ç»Ÿè®¡ä¿¡æ¯
tail -50 dataset_miner_agent.log | grep -A 10 "Agent è®°å¿†ç»Ÿè®¡"

# åº”è¯¥çœ‹åˆ°:
# [Agent è®°å¿†ç»Ÿè®¡]
#   æ€»ç»éªŒæ•°: 24
#   æˆåŠŸç‡: 87.50%
#   å¹³å‡è´¨é‡: 0.78
```

---

## ç¬¬å››æ­¥ï¼šè¿è¡Œå¯¹æ¯”å®éªŒ

### 4.1 è¿è¡Œå®éªŒæ¡†æ¶

```bash
# å®Œæ•´å¯¹æ¯”å®éªŒï¼ˆ3ç¯‡è®ºæ–‡æµ‹è¯•ï¼‰
python3 experiment_framework.py

# é¢„æœŸè€—æ—¶ï¼š10-15åˆ†é’Ÿï¼ˆå–å†³äºç½‘ç»œå’ŒLLMé€Ÿåº¦ï¼‰
```

### 4.2 æŸ¥çœ‹å®éªŒç»“æœ

```bash
# æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶
ls -lh experiments/

# åº”è¯¥æœ‰:
# - workflow_results.jsonl
# - agent_results_no_reflection.jsonl
# - agent_results_with_reflection.jsonl
# - experiment_results.json
# - experiment_report.txt

# æŸ¥çœ‹å¯¹æ¯”æŠ¥å‘Š
cat experiments/experiment_report.txt
```

### 4.3 åˆ†æç»“æœ

```bash
# æ¯”è¾ƒæå–çš„æ•°æ®é›†æ•°é‡
echo "Workflow:"
wc -l experiments/workflow_results.jsonl

echo "Agent (æ— åæ€):"
wc -l experiments/agent_results_no_reflection.jsonl

echo "Agent (æœ‰åæ€):"
wc -l experiments/agent_results_with_reflection.jsonl
```

---

## ç¬¬äº”æ­¥ï¼šå¯è§†åŒ–åˆ†æ

### 5.1 ç”Ÿæˆå¯è§†åŒ–

```bash
# åˆ›å»ºå¯è§†åŒ–ç›®å½•
mkdir -p visualizations

# è¿è¡Œå¯è§†åŒ–è„šæœ¬
python3 visualize_agent.py

# æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨
ls -lh visualizations/

# åº”è¯¥æœ‰:
# - quality_dist.png (è´¨é‡åˆ†å¸ƒ)
# - action_performance.png (åŠ¨ä½œæ€§èƒ½)
# - reflection_impact.png (åæ€å½±å“)
# - agent_summary.txt (æ‘˜è¦æŠ¥å‘Š)
```

### 5.2 æŸ¥çœ‹å›¾è¡¨

```bash
# macOS
open visualizations/*.png

# Linux
xdg-open visualizations/*.png

# æˆ–è€…ç”¨ä½ å–œæ¬¢çš„å›¾ç‰‡æŸ¥çœ‹å™¨
```

### 5.3 é˜…è¯»æ‘˜è¦

```bash
cat visualizations/agent_summary.txt
```

---

## ç¬¬å…­æ­¥ï¼šè°ƒæ•´å’Œä¼˜åŒ–

### 6.1 è°ƒæ•´åæ€é˜ˆå€¼

ç¼–è¾‘ `reflection_engine.py`:

```python
def _should_retry(self, result, quality_score, issues):
    # åŸå§‹: è´¨é‡<0.3 æ—¶é‡è¯•
    if quality_score < 0.3:
        return True

    # ä¿®æ”¹ä¸º: è´¨é‡<0.6 æ—¶é‡è¯•ï¼ˆæ›´ä¸¥æ ¼ï¼‰
    if quality_score < 0.6:
        return True
    return False
```

### 6.2 è°ƒæ•´Agentå‚æ•°

ç¼–è¾‘ `main_agent.py` çš„ `main()` å‡½æ•°:

```python
def main():
    miner = AgentDatasetMiner(
        output_file="outputs/dataset_agent_results.jsonl",
        enable_llm_reflection=True,  # æ”¹ä¸º False ç¦ç”¨LLMåæ€
        max_retries=2,                # æ”¹ä¸º 5 å…è®¸æ›´å¤šé‡è¯•
    )

    # è°ƒæ•´å¤„ç†çš„è®ºæ–‡æ•°é‡
    miner.run(year=2024, max_papers=10)  # ä» 3 æ”¹ä¸º 10
```

### 6.3 æ·»åŠ è‡ªå®šä¹‰çº¦æŸ

åœ¨ `agent_controller.py` ä¸­æ·»åŠ :

```python
class ConstrainedAgent(AgentController):
    """å¸¦çº¦æŸçš„Agent"""

    def _adjust(self, reflection, plan, context, result):
        # å¼ºåˆ¶è¦æ±‚ï¼šè‡³å°‘æå–2ä¸ªæ•°æ®é›†
        if result.metadata.get("datasets_found", 0) < 2:
            logger.info("[çº¦æŸ] æ•°æ®é›†æ•°é‡ä¸è¶³ï¼Œé‡è¯•")
            reflection.needs_retry = True

        return super()._adjust(reflection, plan, context, result)
```

ç„¶ååœ¨ `main_agent.py` ä¸­ä½¿ç”¨:

```python
from agent_controller import ConstrainedAgent

# åœ¨ AgentDatasetMiner.__init__ ä¸­:
self.agent = ConstrainedAgent(...)  # è€Œä¸æ˜¯ AgentController
```

---

## ç¬¬ä¸ƒæ­¥ï¼šæ‰©å±•å®éªŒ

### 7.1 å¢åŠ è®ºæ–‡æ•°é‡

```bash
# å¤„ç†50ç¯‡è®ºæ–‡
python3 -c "
from main_agent import AgentDatasetMiner
miner = AgentDatasetMiner()
miner.run(year=2024, max_papers=50)
"
```

### 7.2 æµ‹è¯•ä¸åŒå¹´ä»½

```bash
# æµ‹è¯•2023å¹´
python3 -c "
from main_agent import AgentDatasetMiner
miner = AgentDatasetMiner(output_file='outputs/neurips_2023_agent.jsonl')
miner.run(year=2023, max_papers=10)
"
```

### 7.3 æµ‹è¯•å…¶ä»–ä¼šè®®

å¦‚æœè¦æµ‹è¯•ICMLæˆ–ICLRï¼Œéœ€è¦åˆ›å»ºå¯¹åº”çš„downloaderï¼ˆå·²æœ‰icml_downloader.pyï¼‰:

```python
# main_agent_icml.py
from main_agent import AgentDatasetMiner
from icml_downloader import ICMLDownloader

# ä¿®æ”¹ AgentDatasetMiner.run() ä¸­çš„ downloader
# downloader = ICMLDownloader(year=year, temp_dir="temp")
```

---

## ç¬¬å…«æ­¥ï¼šæ•°æ®åˆ†æ

### 8.1 å¯¼å‡ºå†³ç­–è½¨è¿¹

åœ¨ `main_agent.py` æœ«å°¾æ·»åŠ :

```python
def export_decision_trace(agent, output_file="decision_trace.json"):
    """å¯¼å‡ºå®Œæ•´çš„å†³ç­–è½¨è¿¹"""
    import json

    trace = []
    for exp in agent.memory.short_term:
        trace.append({
            "action": exp.action.action_type.value,
            "reasoning": exp.action.reasoning,
            "result_success": exp.result.success,
            "quality_score": exp.reflection.quality_score,
            "insights": exp.reflection.insights,
            "needs_retry": exp.reflection.needs_retry
        })

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(trace, f, ensure_ascii=False, indent=2)

    print(f"å†³ç­–è½¨è¿¹å·²å¯¼å‡ºåˆ°: {output_file}")

# åœ¨ main() å‡½æ•°æœ«å°¾è°ƒç”¨
if __name__ == "__main__":
    main()
    # å¦‚æœå·²è¿è¡Œè¿‡ï¼Œå¯ä»¥è¿™æ ·å¯¼å‡º
    # export_decision_trace(miner.agent, "trace.json")
```

### 8.2 åˆ†æåæ€æ¨¡å¼

```bash
# æå–æ‰€æœ‰åæ€æ´å¯Ÿ
python3 -c "
import json

insights = []
with open('memory/long_term_memory.jsonl', 'r') as f:
    for line in f:
        record = json.loads(line)
        exp = record['experience']
        insights.extend(exp['reflection']['insights'])

# ç»Ÿè®¡æœ€å¸¸è§çš„æ´å¯Ÿ
from collections import Counter
common = Counter(insights).most_common(10)

print('æœ€å¸¸è§çš„10ä¸ªæ´å¯Ÿ:')
for insight, count in common:
    print(f'  {count}æ¬¡: {insight}')
"
```

### 8.3 å¯¹æ¯”æ•°æ®é›†æå–æ•ˆæœ

```bash
# æå–æ‰€æœ‰æ•°æ®é›†åç§°è¿›è¡Œå¯¹æ¯”
python3 -c "
import json

def extract_datasets(file):
    datasets = set()
    with open(file, 'r') as f:
        for line in f:
            record = json.loads(line)
            datasets.add(record['name'])
    return datasets

workflow_datasets = extract_datasets('outputs/test_workflow.jsonl')
agent_datasets = extract_datasets('outputs/dataset_agent_results.jsonl')

print(f'Workflowæå–: {len(workflow_datasets)} ä¸ª')
print(f'Agentæå–: {len(agent_datasets)} ä¸ª')
print(f'Agentå¤šæå–: {agent_datasets - workflow_datasets}')
print(f'Agentæ¼æå–: {workflow_datasets - agent_datasets}')
"
```

---

## ç¬¬ä¹æ­¥ï¼šè®ºæ–‡æ’°å†™

### 9.1 æ”¶é›†å®éªŒæ•°æ®

åˆ›å»º `paper_data/` ç›®å½•ï¼š

```bash
mkdir -p paper_data

# å¤åˆ¶å…³é”®ç»“æœ
cp experiments/experiment_report.txt paper_data/
cp visualizations/*.png paper_data/
cp visualizations/agent_summary.txt paper_data/

# å¯¼å‡ºå†³ç­–è½¨è¿¹ï¼ˆç”¨äºæ¡ˆä¾‹åˆ†æï¼‰
python3 -c "
from main_agent import AgentDatasetMiner, export_decision_trace
# å‡è®¾å·²ç»è¿è¡Œè¿‡
# export_decision_trace(miner.agent, 'paper_data/decision_trace.json')
"
```

### 9.2 é€‰æ‹©å…¸å‹æ¡ˆä¾‹

```bash
# ä»æ—¥å¿—ä¸­æå–æœ‰è¶£çš„æ¡ˆä¾‹
grep -B 5 -A 5 "éœ€è¦é‡è¯•" dataset_miner_agent.log > paper_data/retry_cases.txt
grep -B 5 -A 5 "è´¨é‡.*0\.[89]" dataset_miner_agent.log > paper_data/high_quality_cases.txt
```

### 9.3 ç”Ÿæˆè¡¨æ ¼æ•°æ®

åˆ›å»º `generate_tables.py`:

```python
import json
import pandas as pd

# è¯»å–å®éªŒç»“æœ
with open('experiments/experiment_results.json', 'r') as f:
    results = json.load(f)

# ç”Ÿæˆè¡¨æ ¼
df = pd.DataFrame([
    {
        'ç³»ç»Ÿ': res['system_name'],
        'æ•°æ®é›†æ•°': res['total_datasets_extracted'],
        'å¹³å‡è´¨é‡': f"{res['average_quality_score']:.2f}",
        'åæ€æ¬¡æ•°': res['reflection_count'],
        'é‡è¯•æ¬¡æ•°': res['retry_count'],
        'æ€»è€—æ—¶(s)': f"{res['total_time']:.1f}",
    }
    for res in results.values()
])

# å¯¼å‡ºLaTeXè¡¨æ ¼
print(df.to_latex(index=False))

# ä¿å­˜CSV
df.to_csv('paper_data/results_table.csv', index=False)
```

è¿è¡Œ:
```bash
python3 generate_tables.py > paper_data/results_table.tex
```

---

## ç¬¬åæ­¥ï¼šé—®é¢˜æ’æŸ¥

### å¸¸è§é—®é¢˜

#### Q1: æ‰¾ä¸åˆ°è®ºæ–‡

**ç—‡çŠ¶**: "æœªæ‰¾åˆ°ä»»ä½•è®ºæ–‡"

**åŸå› **: 2025å¹´çš„è®ºæ–‡å¯èƒ½è¿˜æœªå‘å¸ƒ

**è§£å†³**:
```python
# æ”¹ç”¨2024å¹´
miner.run(year=2024, max_papers=10)
```

#### Q2: LLMè°ƒç”¨å¤±è´¥

**ç—‡çŠ¶**: "LLMè°ƒç”¨å¤±è´¥: ..."

**åŸå› **: API keyæ— æ•ˆæˆ–ç½‘ç»œé—®é¢˜

**è§£å†³**:
```bash
# æ£€æŸ¥API key
grep "api_key" llm_client.py

# æµ‹è¯•LLMè¿æ¥
python3 -c "
from llm_client import call_gpt4o_text
try:
    resp = call_gpt4o_text('Hello')
    print('LLMè¿æ¥æ­£å¸¸:', resp[:50])
except Exception as e:
    print('LLMè¿æ¥å¤±è´¥:', e)
"
```

#### Q3: å†…å­˜ä¸è¶³

**ç—‡çŠ¶**: MemoryError

**åŸå› **: å¤„ç†è¿‡å¤šè®ºæ–‡

**è§£å†³**:
```python
# å‡å°‘è®ºæ–‡æ•°é‡
miner.run(year=2024, max_papers=5)  # ä»50æ”¹ä¸º5

# æˆ–è€…æ¸…ç†çŸ­æœŸè®°å¿†
agent.memory.clear_short_term()
```

#### Q4: PDFè§£æå¤±è´¥

**ç—‡çŠ¶**: "PDFè§£æå¤±è´¥"

**åŸå› **: PDFæ–‡ä»¶æŸåæˆ–æ ¼å¼ä¸æ”¯æŒ

**è§£å†³**: Agentä¼šè‡ªåŠ¨è·³è¿‡å¤±è´¥çš„è®ºæ–‡ï¼ŒæŸ¥çœ‹æ—¥å¿—äº†è§£è¯¦æƒ…

---

## ğŸ‰ å®Œæˆæ£€æŸ¥æ¸…å•

- [ ] ç³»ç»Ÿæ–‡ä»¶å®Œæ•´
- [ ] ä¾èµ–åŒ…å·²å®‰è£…
- [ ] å¿«é€Ÿæµ‹è¯•é€šè¿‡
- [ ] èƒ½çœ‹åˆ°Agentå†³ç­–è¿‡ç¨‹
- [ ] å¯¹æ¯”å®éªŒå®Œæˆ
- [ ] å¯è§†åŒ–ç”ŸæˆæˆåŠŸ
- [ ] ç†è§£äº†å¦‚ä½•è°ƒæ•´å‚æ•°
- [ ] æ‰©å±•å®éªŒè¿è¡ŒæˆåŠŸ
- [ ] æ•°æ®åˆ†æå®Œæˆ
- [ ] è®ºæ–‡æ•°æ®å·²æ”¶é›†

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

1. **å®Œæ•´æ–‡æ¡£**: `AGENT_SYSTEM_README.md`
2. **å¿«é€Ÿå¼€å§‹**: `QUICK_START.md`
3. **ç ”ç©¶äº®ç‚¹**: `RESEARCH_HIGHLIGHTS.md`
4. **é¡¹ç›®æ€»ç»“**: `PROJECT_SUMMARY.md`
5. **æœ¬æ¸…å•**: `EXECUTION_CHECKLIST.md`

---

## ğŸ†˜ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶: `dataset_miner_agent.log`
2. æ£€æŸ¥é”™è¯¯ä¿¡æ¯: é€šå¸¸æœ‰è¯¦ç»†çš„ traceback
3. æŸ¥é˜…ç›¸å…³æ–‡æ¡£
4. æ£€æŸ¥ä»£ç æ³¨é‡Š

---

**ç¥å®éªŒé¡ºåˆ©ï¼** ğŸš€

è®°ä½ï¼šå…ˆä»å°è§„æ¨¡æµ‹è¯•å¼€å§‹ï¼ˆ3-5ç¯‡è®ºæ–‡ï¼‰ï¼Œç¡®è®¤ç³»ç»Ÿå·¥ä½œæ­£å¸¸åï¼Œå†æ‰©å±•åˆ°æ›´å¤§è§„æ¨¡çš„å®éªŒã€‚
