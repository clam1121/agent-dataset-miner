# ICLR论文数据集提取流程报告

## 一、项目概述

本项目旨在从ICLR（International Conference on Learning Representations）学术论文中自动提取数据集信息，构建结构化的数据集知识库。系统采用流式处理架构，结合PDF解析和GPT-4o大语言模型，实现从论文下载到信息提取的全自动化流程。

## 二、核心流程

### 2.1 整体架构

系统采用模块化设计，主要包含以下组件：
- **下载模块** (`downloader.py`): 从OpenReview平台获取论文
- **解析模块** (`pdf_parser.py`): 提取PDF文本和URL
- **LLM客户端** (`llm_client.py`): 调用GPT-4o进行信息提取
- **主程序** (`main.py`): 协调各模块完成端到端流程

### 2.2 详细流程步骤

#### 步骤1: 论文获取与下载
- 通过OpenReview API连接ICLR会议（默认2025年）
- 筛选Oral、Spotlight、Poster三类论文
- 逐篇下载PDF到临时目录
- 提取论文基本信息（标题、ID、OpenReview链接）

#### 步骤2: PDF解析与文本提取
- 使用PyMuPDF解析PDF文件
- **智能文本提取策略**：
  - 提取前5页文本（通常包含标题、摘要、引言）
  - 提取包含数据集关键词的句子（dataset、benchmark、corpus等）
  - 提取所有URL链接（用于后续数据集链接识别）
- 限制文本长度至25,000字符，避免超出LLM上下文限制

#### 步骤3: 论文元信息提取
- 调用GPT-4o提取论文元信息
- 提取字段：标题、作者列表、会议名称、年份、论文URL
- 使用结构化提示词确保输出格式统一

#### 步骤4: 数据集名称识别
- 调用GPT-4o从论文文本中识别所有数据集名称
- 区分数据集名称和模型名称
- 支持识别论文提出的新数据集

#### 步骤5: 数据集详细信息提取
- 对每个识别出的数据集，单独调用GPT-4o提取详细信息
- 提取字段包括：
  - **content**: 数据集描述（用途、规模、特点）
  - **type**: 数据类型（如多选问题、图像分类、文本生成）
  - **domain**: 应用领域（如NLP、计算机视觉、音频）
  - **fields**: 应用方向（如大模型评估、目标检测）
  - **dataset_link**: 数据集下载链接（从提取的URL中匹配）
  - **platform**: 托管平台（GitHub、HuggingFace、Kaggle等）

#### 步骤6: 结果保存与清理
- 将提取的数据集信息组装成结构化JSON对象
- 立即追加写入JSONL文件（支持中断恢复）
- 删除临时PDF文件释放磁盘空间
- 记录处理日志

### 2.3 流式处理设计

系统采用**流式处理架构**，核心特点：
- **边下载边处理**：每下载一篇论文立即处理，不等待全部下载完成
- **即时保存**：处理完一篇论文立即写入结果，避免内存堆积
- **自动清理**：处理完成后立即删除PDF文件，节省存储空间
- **容错机制**：单篇论文处理失败不影响整体流程，支持中断后继续

## 三、技术特点

### 3.1 智能文本提取
- 优先提取论文前几页（包含核心信息）
- 基于关键词过滤数据集相关句子
- 自动提取和清理URL链接

### 3.2 LLM多轮提取策略
- **第一轮**：提取论文元信息（一次性）
- **第二轮**：识别所有数据集名称（一次性）
- **第三轮**：为每个数据集提取详细信息（循环调用）

### 3.3 错误处理机制
- JSON解析失败时自动重试多种格式（直接JSON、代码块、大括号匹配）
- LLM调用失败时使用默认值，保证流程继续
- 详细的日志记录，便于问题追踪

## 四、输出格式

每条数据集记录包含以下字段：

```json
{
  "dataset id": "001",
  "name": "数据集名称",
  "dataset describe": {
    "content": "数据集详细描述",
    "type": ["数据类型"],
    "domain": ["应用领域"],
    "fields": ["应用方向"]
  },
  "paper_refs": {
    "title": "论文标题",
    "authors": [{"name": "作者", "institution": "机构"}],
    "venue": "ICLR 2025",
    "year": "2025",
    "url": "OpenReview链接",
    "is_fellow": "false"
  },
  "dataset link": "数据集下载链接",
  "platform": "托管平台"
}
```

## 五、性能与资源

- **处理速度**：每篇论文约3-5分钟（取决于论文长度和数据集数量）
- **内存占用**：流式处理，单篇论文处理完成后释放内存
- **存储需求**：临时PDF自动清理，仅保留最终JSONL结果
- **API调用**：每篇论文约3-5次LLM调用（1次元信息 + 1次数据集名称 + N次详细信息）

## 六、使用方式

```bash
# 安装依赖
pip install -r requirements.txt

# 运行主程序
python main.py
```

程序会自动：
1. 连接OpenReview获取ICLR 2025论文列表
2. 逐篇下载、解析、提取数据集信息
3. 保存结果到 `outputs/dataset_iclr_results.jsonl`
4. 记录详细日志到 `dataset_miner.log`

## 七、总结

本系统实现了从ICLR论文中自动提取数据集信息的完整流程，通过结合PDF解析技术和GPT-4o大语言模型，能够高效、准确地识别和提取论文中提到的数据集信息，为构建学术数据集知识库提供了自动化解决方案。流式处理架构确保了系统在处理大量论文时的稳定性和资源效率。

