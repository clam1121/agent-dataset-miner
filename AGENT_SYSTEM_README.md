# Agent-based Dataset Miner

å°†ä¼ ç»Ÿ Workflow è½¬å˜ä¸ºå…·æœ‰è‡ªä¸»å†³ç­–ã€åæ€å’Œå­¦ä¹ èƒ½åŠ›çš„æ™ºèƒ½ä½“ç³»ç»Ÿã€‚

---

## ğŸ¯ ç ”ç©¶ç›®æ ‡

**è¯¾é¢˜**: Agenticæ¨¡å‹åœ¨å¤æ‚å†³ç­–ä»»åŠ¡ä¸­çš„è¡Œä¸ºå¯æ§æ€§æœºåˆ¶ç ”ç©¶

æœ¬ç³»ç»Ÿå®ç°äº†ä¸€ä¸ªå®Œæ•´çš„ **ReAct + Reflection** æ™ºèƒ½ä½“æ¶æ„ï¼Œç”¨äºç ”ç©¶ï¼š
1. Agent å¦‚ä½•åœ¨å¤šæ¬¡å·¥å…·è°ƒç”¨ä¸­è¿›è¡Œè‡ªä¸»å†³ç­–
2. Reflection å¦‚ä½•å¸®åŠ© Agent è‡ªæˆ‘ä¿®æ­£å’Œæ”¹è¿›
3. è®°å¿†ç³»ç»Ÿå¦‚ä½•å½±å“ Agent çš„è¡Œä¸º
4. å¦‚ä½•æ§åˆ¶å’Œå¼•å¯¼ Agent çš„å†³ç­–è¿‡ç¨‹

---

## ğŸ“ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Agent Controller                        â”‚
â”‚            (ReAct + Reflection å¾ªç¯)                     â”‚
â”‚                                                           â”‚
â”‚  1. Observe  â†’ è§‚å¯Ÿç¯å¢ƒå’ŒçŠ¶æ€                            â”‚
â”‚  2. Think    â†’ æ¨ç†ä¸‹ä¸€æ­¥è¡ŒåŠ¨                            â”‚
â”‚  3. Act      â†’ æ‰§è¡ŒåŠ¨ä½œ                                  â”‚
â”‚  4. Reflect  â†’ åæ€ç»“æœè´¨é‡                              â”‚
â”‚  5. Learn    â†’ å­˜å‚¨ç»éªŒåˆ°è®°å¿†                            â”‚
â”‚  6. Adjust   â†’ æ ¹æ®åæ€è°ƒæ•´è®¡åˆ’                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                â”‚
  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
  â”‚ Memory   â”‚    â”‚ Tool     â”‚
  â”‚ System   â”‚    â”‚ Manager  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚
       â”‚                â”‚
  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ çŸ­æœŸè®°å¿† â”‚    â”‚ PDF Parser               â”‚
  â”‚ é•¿æœŸè®°å¿† â”‚    â”‚ Meta Extractor           â”‚
  â”‚ åæ€å­˜å‚¨ â”‚    â”‚ Dataset Finder           â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ Dataset Details Extractorâ”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ æ ¸å¿ƒç»„ä»¶

### 1. Agent Controller (`agent_controller.py`)

**èŒè´£**: æ™ºèƒ½ä½“çš„"å¤§è„‘"ï¼Œå®ç° ReAct å¾ªç¯

**å…³é”®æ–¹æ³•**:
- `process_paper()`: å¤„ç†å•ç¯‡è®ºæ–‡çš„ä¸»å…¥å£
- `_execute_react_loop()`: æ‰§è¡Œå®Œæ•´çš„ ReAct å¾ªç¯
- `_observe()`: è§‚å¯Ÿå½“å‰çŠ¶æ€
- `_think()`: æ¨ç†ä¸‹ä¸€æ­¥è¡ŒåŠ¨
- `_decide_action()`: å†³ç­–å…·ä½“åŠ¨ä½œ
- `_act()`: æ‰§è¡ŒåŠ¨ä½œ
- `_reflect()`: åæ€ç»“æœ
- `_learn()`: å­¦ä¹ å¹¶å­˜å‚¨ç»éªŒ
- `_adjust()`: æ ¹æ®åæ€è°ƒæ•´è®¡åˆ’

**ReAct å¾ªç¯ç¤ºä¾‹**:
```python
while not plan.is_completed():
    # 1. è§‚å¯Ÿ
    observation = agent._observe(goal, plan, context)

    # 2. æ¨ç†
    thought = agent._think(observation, goal, plan)

    # 3. å†³ç­–å¹¶æ‰§è¡Œ
    action = agent._decide_action(thought, goal, plan, context)
    result = agent._act(action)

    # 4. åæ€
    reflection = agent._reflect(action, result, goal, context)

    # 5. å­¦ä¹ 
    agent._learn(action, result, reflection, goal, context)

    # 6. è°ƒæ•´
    should_continue = agent._adjust(reflection, plan, context, result)
```

---

### 2. Reflection Engine (`reflection_engine.py`)

**èŒè´£**: å¯¹ Agent çš„è¡Œä¸ºè¿›è¡Œå¤šç»´åº¦åæ€

**åæ€ç»´åº¦**:
1. **è´¨é‡è¯„ä¼°** (0-1 è¯„åˆ†)
   - ç»“æœçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
   - æ˜¯å¦è¾¾åˆ°é¢„æœŸç›®æ ‡

2. **é—®é¢˜è¯†åˆ«**
   - å‘ç°æ‰§è¡Œä¸­çš„é—®é¢˜
   - è¯†åˆ«æ½œåœ¨é£é™©

3. **æ´å¯Ÿç”Ÿæˆ**
   - ä»ç»éªŒä¸­å­¦åˆ°çš„çŸ¥è¯†
   - æˆåŠŸæˆ–å¤±è´¥çš„åŸå› åˆ†æ

4. **æ”¹è¿›å»ºè®®**
   - å…·ä½“çš„æ”¹è¿›æªæ–½
   - ä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®

**åæ€ç±»å‹**:
- **åŸºç¡€åæ€** (Rule-based): å¿«é€Ÿï¼ŒåŸºäºè§„åˆ™
- **LLM åæ€** (LLM-based): æ·±å…¥ï¼Œä½†æ›´æ…¢

**ç¤ºä¾‹åæ€è¾“å‡º**:
```json
{
  "quality_score": 0.75,
  "success_assessment": "æˆåŠŸï¼šè´¨é‡è‰¯å¥½",
  "insights": [
    "æˆåŠŸæå–äº†3ä¸ªæ•°æ®é›†",
    "URLé“¾æ¥è¯†åˆ«å‡†ç¡®"
  ],
  "issues_found": [
    "ä¸€ä¸ªæ•°æ®é›†çš„æè¿°ä¸å®Œæ•´"
  ],
  "suggested_improvements": [
    "æ‰©å¤§æœç´¢èŒƒå›´åˆ°å…¨æ–‡",
    "ä½¿ç”¨æ›´ç²¾ç¡®çš„æå–prompt"
  ],
  "needs_retry": false,
  "needs_replan": false
}
```

---

### 3. Memory System (`memory_system.py`)

**èŒè´£**: å­˜å‚¨å’Œæ£€ç´¢ Agent çš„ç»éªŒ

**è®°å¿†ç±»å‹**:

1. **çŸ­æœŸè®°å¿†** (Short-term Memory)
   - å½“å‰ä¼šè¯çš„æ‰§è¡Œå†å²
   - æœ€è¿‘çš„ç»éªŒï¼ˆæœ€å¤š100æ¡ï¼‰
   - ç”¨äºå¿«é€Ÿæ£€ç´¢

2. **é•¿æœŸè®°å¿†** (Long-term Memory)
   - é‡è¦çš„ç»éªŒï¼ˆé«˜è´¨é‡æˆ–å¤±è´¥ä½†æœ‰æ´å¯Ÿï¼‰
   - æŒ‰æ¨¡å¼åˆ†ç±»å­˜å‚¨
   - æŒä¹…åŒ–åˆ°ç£ç›˜

3. **åæ€å­˜å‚¨** (Reflection Store)
   - æ‰€æœ‰åæ€è®°å½•
   - ç”¨äºåˆ†æ Agent çš„æ€è€ƒè¿‡ç¨‹

**å…³é”®æ–¹æ³•**:
- `store_experience()`: å­˜å‚¨ç»éªŒ
- `retrieve_similar_experiences()`: æ£€ç´¢ç›¸ä¼¼ç»éªŒ
- `get_action_success_rate()`: è·å–åŠ¨ä½œæˆåŠŸç‡
- `summarize_session()`: æ€»ç»“ä¼šè¯

**ç»éªŒç»“æ„**:
```python
Experience {
    goal: Goal              # ç›®æ ‡
    action: Action          # åŠ¨ä½œ
    result: ToolResult      # ç»“æœ
    reflection: Reflection  # åæ€
    is_successful: bool     # æ˜¯å¦æˆåŠŸ
    is_significant: bool    # æ˜¯å¦é‡è¦
    pattern: str            # ç»éªŒæ¨¡å¼
}
```

---

### 4. Tool Manager (`tool_manager.py`)

**èŒè´£**: ç®¡ç†å’Œæ‰§è¡Œæ‰€æœ‰å·¥å…·

**å·²æ³¨å†Œå·¥å…·**:
- `PDFParserTool`: è§£æ PDF
- `MetaExtractorTool`: æå–è®ºæ–‡å…ƒä¿¡æ¯
- `DatasetFinderTool`: æå–æ•°æ®é›†åç§°
- `DatasetDetailsExtractorTool`: æå–æ•°æ®é›†è¯¦ç»†ä¿¡æ¯

**å·¥å…·æ‰§è¡Œæµç¨‹**:
```python
# 1. æ ¹æ®åŠ¨ä½œç±»å‹é€‰æ‹©å·¥å…·
tool = tool_manager.tools[action.action_type]

# 2. æ‰§è¡Œå·¥å…·
result = tool.execute(action.params)

# 3. è®°å½•æ‰§è¡Œå†å²
tool_manager.execution_history.append({
    "action_id": action.action_id,
    "success": result.success,
    "execution_time": result.execution_time
})
```

---

## ğŸ”„ Reflection åœ¨å¤šæ¬¡å·¥å…·è°ƒç”¨ä¸­çš„ä½œç”¨

### åœºæ™¯1: æ•°æ®é›†æå–ä¸å®Œæ•´

```
Iteration 1:
  [åŠ¨ä½œ] æå–æ•°æ®é›†åç§°
  [ç»“æœ] æ‰¾åˆ° 1 ä¸ª: ["ImageNet"]

  [åæ€]
    è´¨é‡è¯„åˆ†: 0.4
    é—®é¢˜: "è®ºæ–‡æ‘˜è¦æåˆ° 'multiple benchmarks'ï¼Œä½†åªæ‰¾åˆ°1ä¸ª"
    å»ºè®®: "æ‰©å¤§æœç´¢èŒƒå›´ï¼Œä½¿ç”¨æ›´å®½æ³›çš„å…³é”®è¯"
    å†³ç­–: needs_retry = True

Iteration 2: (é‡è¯•)
  [åŠ¨ä½œ] æå–æ•°æ®é›†åç§° (æ”¹è¿›çš„ç­–ç•¥)
  [ç»“æœ] æ‰¾åˆ° 3 ä¸ª: ["ImageNet", "CIFAR-10", "CustomBench"]

  [åæ€]
    è´¨é‡è¯„åˆ†: 0.85
    æ´å¯Ÿ: "ä½¿ç”¨å…¨æ–‡æœç´¢æ•ˆæœæ›´å¥½"
    å†³ç­–: needs_retry = False, ç»§ç»­ä¸‹ä¸€æ­¥
```

### åœºæ™¯2: PDF è§£æå¤±è´¥åçš„ç­–ç•¥è°ƒæ•´

```
Iteration 1:
  [åŠ¨ä½œ] è§£æ PDF
  [ç»“æœ] å¤±è´¥ (ç¼–ç é”™è¯¯)

  [åæ€]
    é—®é¢˜: "PDFæ–‡ä»¶ç¼–ç å¼‚å¸¸"
    å»ºè®®: "å°è¯•ä½¿ç”¨å¤‡ç”¨è§£æå™¨æˆ–è·³è¿‡æ­¤æ–‡ä»¶"
    å†³ç­–: needs_replan = True

Iteration 2: (è°ƒæ•´ç­–ç•¥)
  [åŠ¨ä½œ] è·³è¿‡é—®é¢˜è®ºæ–‡ï¼Œæ ‡è®°å¾…äººå·¥å¤„ç†
  [ç»“æœ] æˆåŠŸ

  [å­¦ä¹ ] å°†æ­¤ç»éªŒå­˜å…¥é•¿æœŸè®°å¿†ï¼Œä¸‹æ¬¡é‡åˆ°ç±»ä¼¼é—®é¢˜ç›´æ¥è·³è¿‡
```

### åœºæ™¯3: ä»å†å²ç»éªŒä¸­å­¦ä¹ 

```
å½“å‰ä»»åŠ¡: æå– NeurIPS è®ºæ–‡çš„æ•°æ®é›†

[æ£€ç´¢è®°å¿†]
  ç›¸ä¼¼ç»éªŒ: "ä¸Šæ¬¡å¤„ç† NeurIPS è®ºæ–‡æ—¶ï¼Œæ•°æ®é›†é€šå¸¸åœ¨ Experiments éƒ¨åˆ†"

[å†³ç­–]
  è°ƒæ•´ç­–ç•¥: é‡ç‚¹å…³æ³¨ Experiments å’Œ Datasets éƒ¨åˆ†

[æ‰§è¡Œ]
  æå–æ•ˆæœæ›´å¥½ï¼Œè´¨é‡è¯„åˆ† 0.9

[åæ€]
  æ´å¯Ÿ: "åˆ©ç”¨å†å²ç»éªŒæ˜¾è‘—æå‡äº†æå–å‡†ç¡®ç‡"

[å­¦ä¹ ]
  å¼ºåŒ–è¯¥æ¨¡å¼ï¼Œå­˜å…¥é•¿æœŸè®°å¿†
```

---

## ğŸ†š ä¸åŸå§‹ Workflow çš„å¯¹æ¯”

| ç»´åº¦ | Workflow | Agent (æ— åæ€) | Agent (æœ‰åæ€) |
|------|----------|----------------|----------------|
| **å†³ç­–æ–¹å¼** | å›ºå®šæµç¨‹ | åŠ¨æ€å†³ç­– | åæ€åè°ƒæ•´ |
| **é”™è¯¯å¤„ç†** | è·³è¿‡æˆ–ä¸­æ­¢ | é‡è¯• | è‡ªæˆ‘ä¿®æ­£ |
| **è´¨é‡è¯„ä¼°** | æ—  | åŸºç¡€è¯„åˆ† | æ·±åº¦è¯„ä¼° |
| **ç»éªŒç§¯ç´¯** | æ—  | çŸ­æœŸè®°å¿† | é•¿çŸ­æœŸè®°å¿† |
| **é€æ˜åº¦** | ä½ | ä¸­ | é«˜ï¼ˆæœ‰æ¨ç†æ—¥å¿—ï¼‰|
| **å¯æ§æ€§** | ä½ | ä¸­ | é«˜ï¼ˆå¯è°ƒæ•´åæ€å‚æ•°ï¼‰|
| **æ•ˆç‡** | é«˜ | ä¸­ | è¾ƒä½ï¼ˆå¤šæ¬¡LLMè°ƒç”¨ï¼‰|

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. è¿è¡Œ Agent ç³»ç»Ÿ

```bash
# åŸºç¡€è¿è¡Œï¼ˆæµ‹è¯•3ç¯‡è®ºæ–‡ï¼‰
python main_agent.py

# ä¿®æ”¹å‚æ•°
python -c "
from main_agent import AgentDatasetMiner

miner = AgentDatasetMiner(
    output_file='outputs/my_results.jsonl',
    enable_llm_reflection=True,  # å¯ç”¨LLMåæ€
    max_retries=2                 # æœ€å¤§é‡è¯•æ¬¡æ•°
)

miner.run(year=2024, max_papers=10)
"
```

### 2. è¿è¡Œå¯¹æ¯”å®éªŒ

```bash
# å¯¹æ¯” Workflow vs Agent (æ— åæ€) vs Agent (æœ‰åæ€)
python experiment_framework.py

# æŸ¥çœ‹ç»“æœ
cat experiments/experiment_report.txt
```

### 3. è‡ªå®šä¹‰åæ€ç­–ç•¥

```python
from reflection_engine import ReflectionEngine

# åˆ›å»ºè‡ªå®šä¹‰åæ€å¼•æ“
engine = ReflectionEngine(enable_llm_reflection=True)

# ä¿®æ”¹åæ€å‚æ•°
class CustomReflectionEngine(ReflectionEngine):
    def _assess_quality(self, action, result):
        # è‡ªå®šä¹‰è´¨é‡è¯„ä¼°é€»è¾‘
        score = super()._assess_quality(action, result)

        # æ·»åŠ é¢å¤–çš„è´¨é‡æ£€æŸ¥
        if result.metadata.get("datasets_found", 0) == 0:
            score *= 0.5  # é™ä½åˆ†æ•°

        return score
```

---

## ğŸ“Š å®éªŒè®¾è®¡

### è¯„ä¼°æŒ‡æ ‡

1. **ä»»åŠ¡å®Œæˆåº¦**
   - æ•°æ®é›†æå–å¬å›ç‡
   - æ•°æ®é›†æå–å‡†ç¡®ç‡
   - å¹³å‡æ¯ç¯‡è®ºæ–‡æå–çš„æ•°æ®é›†æ•°

2. **è´¨é‡æŒ‡æ ‡**
   - å¹³å‡è´¨é‡è¯„åˆ†
   - é«˜è´¨é‡ç»“æœæ¯”ä¾‹ (>0.8)
   - ä½è´¨é‡ç»“æœæ¯”ä¾‹ (<0.4)

3. **è¡Œä¸ºå¯æ§æ€§**
   - å†³ç­–é€æ˜åº¦ï¼ˆæœ‰æ¨ç†æ—¥å¿—ï¼‰
   - åæ€è§¦å‘é¢‘ç‡
   - è‡ªæˆ‘ä¿®æ­£æˆåŠŸç‡

4. **æ•ˆç‡æŒ‡æ ‡**
   - æ€»æ‰§è¡Œæ—¶é—´
   - LLM è°ƒç”¨æ¬¡æ•°
   - æ¯ç¯‡è®ºæ–‡å¹³å‡è€—æ—¶

### å®éªŒç»„

1. **Baseline**: åŸå§‹ Workflow
2. **Agent-NoReflection**: Agentï¼ˆä»…åŸºç¡€åæ€ï¼‰
3. **Agent-WithReflection**: Agentï¼ˆLLM æ·±åº¦åæ€ï¼‰

### å®éªŒå˜é‡

**æ§åˆ¶å˜é‡**:
- æ•°æ®é›†ï¼ˆåŒæ ·çš„è®ºæ–‡ï¼‰
- LLM æ¨¡å‹ï¼ˆGPT-4oï¼‰
- æç¤ºè¯ï¼ˆç›¸åŒï¼‰

**å®éªŒå˜é‡**:
- æ˜¯å¦å¯ç”¨åæ€
- åæ€æ·±åº¦ï¼ˆåŸºç¡€ vs LLMï¼‰
- æœ€å¤§é‡è¯•æ¬¡æ•°

---

## ğŸ”¬ ç ”ç©¶ä»·å€¼

### 1. è¡Œä¸ºå¯æ§æ€§æœºåˆ¶

**é€æ˜åº¦**:
- æ¯ä¸ªå†³ç­–éƒ½æœ‰æ˜ç¡®çš„æ¨ç†è¿‡ç¨‹
- åæ€æä¾›äº†å†³ç­–çš„ä¾æ®
- å¯ä»¥è¿½è¸ªå®Œæ•´çš„å†³ç­–é“¾

**å¯å¹²é¢„æ€§**:
- å¯ä»¥åœ¨åæ€é˜¶æ®µæ³¨å…¥çº¦æŸ
- å¯ä»¥è°ƒæ•´è´¨é‡é˜ˆå€¼
- å¯ä»¥ä¿®æ”¹é‡è¯•ç­–ç•¥

**ç¤ºä¾‹**:
```python
# æ·»åŠ çº¦æŸï¼šæ•°æ®é›†æå–çš„è´¨é‡å¿…é¡» >0.7
class ConstrainedAgent(AgentController):
    def _adjust(self, reflection, plan, context, result):
        if reflection.quality_score < 0.7:
            logger.info("[çº¦æŸ] è´¨é‡ä¸è¾¾æ ‡ï¼Œå¼ºåˆ¶é‡è¯•")
            return True  # é‡è¯•
        return super()._adjust(reflection, plan, context, result)
```

### 2. Reflection çš„ä½œç”¨

**è´¨é‡æå‡**:
- é€šè¿‡åæ€å‘ç°ä½è´¨é‡ç»“æœ
- å»ºè®®æ”¹è¿›æªæ–½
- è‡ªåŠ¨é‡è¯•ç›´åˆ°è¾¾æ ‡

**è‡ªæˆ‘ä¿®æ­£**:
- æ£€æµ‹é”™è¯¯å¹¶è‡ªåŠ¨çº æ­£
- è°ƒæ•´ç­–ç•¥åº”å¯¹å¤±è´¥
- ä»å¤±è´¥ä¸­å­¦ä¹ 

**ç¤ºä¾‹ç»Ÿè®¡**:
```
å®éªŒç»“æœï¼ˆ10ç¯‡è®ºæ–‡ï¼‰:
- Workflow: æå–15ä¸ªæ•°æ®é›†ï¼Œ0æ¬¡ä¿®æ­£
- Agent (æ— åæ€): æå–17ä¸ªæ•°æ®é›†ï¼Œ2æ¬¡é‡è¯•
- Agent (æœ‰åæ€): æå–20ä¸ªæ•°æ®é›†ï¼Œ5æ¬¡é‡è¯•ï¼Œ3æ¬¡è‡ªæˆ‘ä¿®æ­£
```

### 3. Memory çš„å½±å“

**ç»éªŒç§¯ç´¯**:
- Agent åœ¨å¤„ç†è¿‡ç¨‹ä¸­ç§¯ç´¯ç»éªŒ
- åç»­ä»»åŠ¡å¯ä»¥åˆ©ç”¨å†å²ç»éªŒ
- ç›¸ä¼¼æƒ…å†µä¸‹å†³ç­–æ›´å‡†ç¡®

**æ¨¡å¼è¯†åˆ«**:
- è¯†åˆ«æˆåŠŸæ¨¡å¼å¹¶å¤ç”¨
- è¯†åˆ«å¤±è´¥æ¨¡å¼å¹¶é¿å…
- å»ºç«‹é¢†åŸŸçŸ¥è¯†åº“

---

## ğŸ“ æ—¥å¿—å’Œå¯è§†åŒ–

### 1. Agent å†³ç­–æ—¥å¿—

```
============================================================
[è§‚å¯Ÿ] å½“å‰æ­¥éª¤: extract_datasets
[æ¨ç†] ç›®æ ‡æ˜¯æå–è®ºæ–‡ä¸­çš„æ•°æ®é›†ä¿¡æ¯ã€‚å½“å‰éœ€è¦æ‰§è¡Œ: extract_datasets
       å‚è€ƒç»éªŒ: è¿‡å»æˆåŠŸç»éªŒ: æˆåŠŸï¼šé«˜è´¨é‡å®Œæˆ
[åŠ¨ä½œ] extract_datasets
[ç»“æœ] âœ“ æˆåŠŸ (è€—æ—¶: 2.34s)
[åæ€] è´¨é‡=0.85, è¿›åº¦=0.50
[æ´å¯Ÿ] æˆåŠŸæå–äº†3ä¸ªæ•°æ®é›†; URLé“¾æ¥è¯†åˆ«å‡†ç¡®
============================================================
```

### 2. åæ€è¯¦æƒ…

```json
{
  "reflection_id": "refl_a3f9b2c1",
  "quality_score": 0.85,
  "goal_progress": 0.50,
  "success_assessment": "æˆåŠŸï¼šé«˜è´¨é‡å®Œæˆ",
  "insights": [
    "æˆåŠŸæå–äº†3ä¸ªæ•°æ®é›†",
    "URLé“¾æ¥è¯†åˆ«å‡†ç¡®"
  ],
  "issues_found": [],
  "suggested_improvements": [
    "å¯ä»¥è¿›ä¸€æ­¥éªŒè¯æ•°æ®é›†é“¾æ¥çš„æœ‰æ•ˆæ€§"
  ],
  "needs_retry": false,
  "needs_replan": false
}
```

### 3. è®°å¿†ç»Ÿè®¡

```
[Agent è®°å¿†ç»Ÿè®¡]
  æ€»ç»éªŒæ•°: 24
  æˆåŠŸç‡: 87.50%
  å¹³å‡è´¨é‡: 0.78
  é‡è¦ç»éªŒ: 5

[æœ€è¿‘çš„æ´å¯Ÿ]
  - ä½¿ç”¨å…¨æ–‡æœç´¢æ•ˆæœæ›´å¥½
  - PDFè§£æéœ€è¦å¤„ç†ç¼–ç å¼‚å¸¸
  - æ•°æ®é›†é€šå¸¸åœ¨Experimentséƒ¨åˆ†
```

---

## ğŸ“ è®ºæ–‡å†™ä½œè¦ç‚¹

### 1. ç³»ç»Ÿè®¾è®¡

**æ ‡é¢˜**: "åŸºäºReActå’ŒReflectionçš„æ™ºèƒ½æ•°æ®é›†æŒ–æ˜ç³»ç»Ÿ"

**æ ¸å¿ƒè´¡çŒ®**:
1. å®ç°äº†å®Œæ•´çš„ ReAct + Reflection æ¶æ„
2. è®¾è®¡äº†å¤šç»´åº¦çš„åæ€æœºåˆ¶
3. æ„å»ºäº†çŸ­æœŸ/é•¿æœŸè®°å¿†ç³»ç»Ÿ
4. æå‡ºäº†è¡Œä¸ºå¯æ§æ€§çš„è¯„ä¼°æ¡†æ¶

### 2. å®éªŒè®¾è®¡

**å¯¹æ¯”å®éªŒ**:
- Baseline (Workflow) vs Agent (No Reflection) vs Agent (With Reflection)

**è¯„ä¼°ç»´åº¦**:
- ä»»åŠ¡å®Œæˆè´¨é‡
- å†³ç­–é€æ˜åº¦
- é”™è¯¯è‡ªæˆ‘ä¿®æ­£èƒ½åŠ›
- å¯æ§æ€§å’Œå¯è§£é‡Šæ€§

### 3. ç ”ç©¶å‘ç°

**Reflection çš„ä»·å€¼**:
- æé«˜ä»»åŠ¡å®Œæˆè´¨é‡ X%
- å®ç°è‡ªæˆ‘ä¿®æ­£ Y æ¬¡
- å†³ç­–é€æ˜åº¦æå‡ Z%

**è¡Œä¸ºå¯æ§æ€§**:
- é€šè¿‡è°ƒæ•´åæ€é˜ˆå€¼å¯ä»¥æ§åˆ¶è´¨é‡/æ•ˆç‡æƒè¡¡
- é€šè¿‡çº¦æŸæ³¨å…¥å¯ä»¥é™åˆ¶ Agent è¡Œä¸º
- å®Œæ•´çš„å†³ç­–æ—¥å¿—æ”¯æŒäº‹ååˆ†æ

---

## ğŸ”§ æ‰©å±•å’Œæ”¹è¿›

### 1. å¢å¼ºåæ€èƒ½åŠ›

```python
# å¤šè½®åæ€
class MultiRoundReflectionEngine(ReflectionEngine):
    def reflect(self, action, result, goal, context, history):
        # ç¬¬ä¸€è½®ï¼šå¿«é€Ÿåæ€
        reflection1 = super().reflect(...)

        # å¦‚æœè´¨é‡ä¸ä½³ï¼Œè¿›è¡Œæ·±åº¦åæ€
        if reflection1.quality_score < 0.6:
            reflection2 = self._deep_reflection(...)
            return reflection2

        return reflection1
```

### 2. å¢åŠ æ›´å¤šå·¥å…·

```python
# URLéªŒè¯å·¥å…·
class URLValidatorTool(BaseTool):
    def execute(self, params):
        url = params['url']
        # éªŒè¯URLæ˜¯å¦æœ‰æ•ˆ
        is_valid = self._check_url(url)
        return ToolResult(...)

# æ³¨å†Œåˆ°Tool Manager
tool_manager.register_tool(
    ActionType.VALIDATE_URL,
    URLValidatorTool()
)
```

### 3. å®ç°æ›´å¤æ‚çš„è§„åˆ’

```python
class HierarchicalPlanner:
    """åˆ†å±‚è§„åˆ’å™¨"""
    def create_plan(self, goal):
        # é«˜å±‚è§„åˆ’
        high_level_steps = self._decompose_goal(goal)

        # ä¸ºæ¯ä¸ªé«˜å±‚æ­¥éª¤åˆ›å»ºè¯¦ç»†è®¡åˆ’
        detailed_plans = []
        for step in high_level_steps:
            sub_plan = self._create_sub_plan(step)
            detailed_plans.append(sub_plan)

        return HierarchicalPlan(high_level_steps, detailed_plans)
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

1. **ReAct**: Yao et al. "ReAct: Synergizing Reasoning and Acting in Language Models" (2022)
2. **Reflection**: Shinn et al. "Reflexion: Language Agents with Verbal Reinforcement Learning" (2023)
3. **Agent Architecture**: Wang et al. "A Survey on Large Language Model based Autonomous Agents" (2023)

---

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»ç ”ç©¶å›¢é˜Ÿã€‚

---

**ç¥ç ”ç©¶é¡ºåˆ©ï¼** ğŸ‰
