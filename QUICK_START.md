# ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

## ç›®å½•

1. [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
2. [æ–‡ä»¶ç»“æ„](#æ–‡ä»¶ç»“æ„)
3. [è¿è¡Œç¤ºä¾‹](#è¿è¡Œç¤ºä¾‹)
4. [å…³é”®æ¦‚å¿µ](#å…³é”®æ¦‚å¿µ)
5. [è°ƒè¯•å’Œç›‘æ§](#è°ƒè¯•å’Œç›‘æ§)

---

## ç³»ç»Ÿæ¦‚è¿°

ä½ ç°åœ¨æœ‰ä¸¤ä¸ªç‰ˆæœ¬çš„æ•°æ®é›†æŒ–æ˜å™¨ï¼š

1. **åŸå§‹ Workflow** (`main_neurips.py`) - å›ºå®šæµç¨‹ï¼Œæ— åæ€
2. **Agent ç³»ç»Ÿ** (`main_agent.py`) - æ™ºèƒ½å†³ç­–ï¼Œæœ‰åæ€å’Œå­¦ä¹ èƒ½åŠ›

---

## æ–‡ä»¶ç»“æ„

```
dataset_miner/
â”œâ”€â”€ # æ ¸å¿ƒ Agent ç»„ä»¶
â”œâ”€â”€ agent_core.py              # æ•°æ®ç»“æ„å®šä¹‰
â”œâ”€â”€ agent_controller.py        # Agent æ§åˆ¶å™¨ (ReAct å¾ªç¯)
â”œâ”€â”€ memory_system.py           # è®°å¿†ç³»ç»Ÿ
â”œâ”€â”€ reflection_engine.py       # åæ€å¼•æ“
â”œâ”€â”€ tool_manager.py            # å·¥å…·ç®¡ç†å™¨
â”‚
â”œâ”€â”€ # ä¸»ç¨‹åº
â”œâ”€â”€ main_neurips.py            # åŸå§‹ Workflow
â”œâ”€â”€ main_agent.py              # Agent ç³»ç»Ÿ
â”œâ”€â”€ experiment_framework.py    # å¯¹æ¯”å®éªŒæ¡†æ¶
â”‚
â”œâ”€â”€ # å·¥å…·æ¨¡å—ï¼ˆå…±ç”¨ï¼‰
â”œâ”€â”€ pdf_parser.py              # PDF è§£æ
â”œâ”€â”€ llm_client.py              # LLM è°ƒç”¨
â”œâ”€â”€ prompts.py                 # æç¤ºè¯æ¨¡æ¿
â”œâ”€â”€ neurips_downloader.py      # è®ºæ–‡ä¸‹è½½å™¨
â”‚
â””â”€â”€ # æ–‡æ¡£
    â”œâ”€â”€ AGENT_SYSTEM_README.md # å®Œæ•´æ–‡æ¡£
    â””â”€â”€ QUICK_START.md         # æœ¬æ–‡ä»¶
```

---

## è¿è¡Œç¤ºä¾‹

### 1ï¸âƒ£ è¿è¡ŒåŸå§‹ Workflowï¼ˆä½œä¸ºå¯¹ç…§ï¼‰

```bash
cd /Users/bytedance/Desktop/paper_agent/dataset_miner

# æµ‹è¯•ï¼šå¤„ç†2024å¹´çš„å‰3ç¯‡è®ºæ–‡
python3 main_neurips.py
```

**è¾“å‡º**:
- æ–‡ä»¶: `outputs/dataset_neurips_results.jsonl`
- æ—¥å¿—: `dataset_miner_neurips.log`

---

### 2ï¸âƒ£ è¿è¡Œ Agent ç³»ç»Ÿ

```bash
# æµ‹è¯•ï¼šå¤„ç†å‰3ç¯‡è®ºæ–‡
python3 main_agent.py
```

**è¾“å‡º**:
- æ–‡ä»¶: `outputs/dataset_agent_results.jsonl`
- æ—¥å¿—: `dataset_miner_agent.log`
- è®°å¿†: `memory/long_term_memory.jsonl`

**æŸ¥çœ‹ Agent å†³ç­–è¿‡ç¨‹**:
```bash
# æŸ¥çœ‹æ—¥å¿—ä¸­çš„åæ€å’Œå†³ç­–
tail -f dataset_miner_agent.log | grep -E "\[è§‚å¯Ÿ\]|\[æ¨ç†\]|\[åŠ¨ä½œ\]|\[åæ€\]"
```

---

### 3ï¸âƒ£ è¿è¡Œå¯¹æ¯”å®éªŒ

```bash
# å®Œæ•´å¯¹æ¯”ï¼šWorkflow vs Agent(æ— åæ€) vs Agent(æœ‰åæ€)
python3 experiment_framework.py
```

**è¾“å‡º**:
- `experiments/workflow_results.jsonl`
- `experiments/agent_results_no_reflection.jsonl`
- `experiments/agent_results_with_reflection.jsonl`
- `experiments/experiment_report.txt` - å¯¹æ¯”æŠ¥å‘Š
- `experiments/experiment.log`

**æŸ¥çœ‹æŠ¥å‘Š**:
```bash
cat experiments/experiment_report.txt
```

---

## å…³é”®æ¦‚å¿µ

### 1. ReAct å¾ªç¯

Agent çš„æ ¸å¿ƒå†³ç­–å¾ªç¯ï¼š

```
loop:
  Observe  â†’ è§‚å¯Ÿå½“å‰çŠ¶æ€
  Think    â†’ æ¨ç†ä¸‹ä¸€æ­¥
  Act      â†’ æ‰§è¡ŒåŠ¨ä½œ
  Reflect  â†’ åæ€ç»“æœ
  Learn    â†’ å­˜å‚¨ç»éªŒ
  Adjust   â†’ è°ƒæ•´è®¡åˆ’
```

**ç¤ºä¾‹æ—¥å¿—**:
```
============================================================
[è§‚å¯Ÿ] å½“å‰æ­¥éª¤: extract_datasets
[æ¨ç†] ç›®æ ‡æ˜¯æå–è®ºæ–‡ä¸­çš„æ•°æ®é›†ä¿¡æ¯...
[åŠ¨ä½œ] extract_datasets
[ç»“æœ] âœ“ æˆåŠŸ (è€—æ—¶: 2.34s)
[åæ€] è´¨é‡=0.85, è¿›åº¦=0.50
[æ´å¯Ÿ] æˆåŠŸæå–äº†3ä¸ªæ•°æ®é›†
============================================================
```

---

### 2. Reflectionï¼ˆåæ€ï¼‰

Agent è¯„ä¼°è‡ªå·±è¡Œä¸ºçš„æœºåˆ¶ï¼š

**åŸºç¡€åæ€** (æ€»æ˜¯æ‰§è¡Œ):
- å¿«é€Ÿï¼ŒåŸºäºè§„åˆ™
- è¯„ä¼°è´¨é‡ã€è¯†åˆ«é—®é¢˜
- å†³å®šæ˜¯å¦é‡è¯•

**LLM åæ€** (å¯é€‰):
- æ·±å…¥ï¼Œä½¿ç”¨ LLM
- ç”Ÿæˆæ´å¯Ÿå’Œæ”¹è¿›å»ºè®®
- æ›´æ…¢ä½†æ›´æ™ºèƒ½

**æ§åˆ¶åæ€**:
```python
# åœ¨ main_agent.py ä¸­ä¿®æ”¹
miner = AgentDatasetMiner(
    enable_llm_reflection=True,  # True=æ·±åº¦åæ€, False=ä»…åŸºç¡€åæ€
    max_retries=2                 # æœ€å¤§é‡è¯•æ¬¡æ•°
)
```

---

### 3. Memoryï¼ˆè®°å¿†ï¼‰

Agent å¦‚ä½•å­¦ä¹ å’Œæ”¹è¿›ï¼š

**çŸ­æœŸè®°å¿†**:
- å½“å‰ä¼šè¯çš„ç»éªŒ
- ç”¨äºå¿«é€Ÿæ£€ç´¢

**é•¿æœŸè®°å¿†**:
- é‡è¦ç»éªŒçš„æŒä¹…åŒ–
- è·¨ä¼šè¯ä½¿ç”¨

**æŸ¥çœ‹è®°å¿†**:
```python
# åœ¨ä»£ç ä¸­æŸ¥çœ‹
memory_summary = agent.memory.summarize_session()
print(memory_summary)

# è¾“å‡º:
# {
#   "total_experiences": 24,
#   "successful": 20,
#   "failed": 4,
#   "success_rate": 0.833,
#   "average_quality_score": 0.78,
#   "recent_insights": ["æ´å¯Ÿ1", "æ´å¯Ÿ2", "æ´å¯Ÿ3"]
# }
```

---

### 4. è´¨é‡è¯„åˆ†

Agent å¦‚ä½•è¯„ä¼°ç»“æœè´¨é‡ï¼š

| è¯„åˆ† | å«ä¹‰ | Agent è¡Œä¸º |
|------|------|-----------|
| 0.8-1.0 | é«˜è´¨é‡ | ç»§ç»­ä¸‹ä¸€æ­¥ |
| 0.6-0.8 | è‰¯å¥½ | ç»§ç»­ï¼Œä½†è®°å½•æ”¹è¿›å»ºè®® |
| 0.4-0.6 | ä¸€èˆ¬ | è€ƒè™‘é‡è¯• |
| 0.0-0.4 | ä½è´¨é‡ | å¼ºåˆ¶é‡è¯•æˆ–é‡æ–°è§„åˆ’ |

---

## è°ƒè¯•å’Œç›‘æ§

### æŸ¥çœ‹å®æ—¶å†³ç­–è¿‡ç¨‹

```bash
# ç»ˆç«¯1: è¿è¡Œ Agent
python3 main_agent.py

# ç»ˆç«¯2: å®æ—¶æŸ¥çœ‹åæ€
tail -f dataset_miner_agent.log | grep "\[åæ€\]"
```

---

### ä¿®æ”¹åæ€é˜ˆå€¼

```python
# åœ¨ reflection_engine.py ä¸­ä¿®æ”¹ _should_retry()
def _should_retry(self, result, quality_score, issues):
    # åŸå§‹: è´¨é‡<0.3 æ—¶é‡è¯•
    if quality_score < 0.3:
        return True

    # ä¿®æ”¹ä¸º: è´¨é‡<0.6 æ—¶é‡è¯•ï¼ˆæ›´ä¸¥æ ¼ï¼‰
    if quality_score < 0.6:
        return True
```

---

### æ·»åŠ è‡ªå®šä¹‰çº¦æŸ

```python
# åœ¨ agent_controller.py ä¸­æ·»åŠ 
class ConstrainedAgent(AgentController):
    def _adjust(self, reflection, plan, context, result):
        # å¼ºåˆ¶è¦æ±‚ï¼šè‡³å°‘æå–2ä¸ªæ•°æ®é›†
        if result.metadata.get("datasets_found", 0) < 2:
            logger.info("[çº¦æŸ] æ•°æ®é›†æ•°é‡ä¸è¶³ï¼Œé‡è¯•")
            reflection.needs_retry = True

        return super()._adjust(reflection, plan, context, result)
```

---

### å¯¼å‡ºå†³ç­–è½¨è¿¹

```python
# æ·»åŠ åˆ° main_agent.py
def export_decision_trace(agent, output_file="decision_trace.json"):
    """å¯¼å‡ºå®Œæ•´çš„å†³ç­–è½¨è¿¹"""
    trace = []

    for exp in agent.memory.short_term:
        trace.append({
            "action": exp.action.action_type.value,
            "reasoning": exp.action.reasoning,
            "result_success": exp.result.success,
            "quality_score": exp.reflection.quality_score,
            "insights": exp.reflection.insights,
            "needs_retry": exp.reflection.needs_retry
        })

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(trace, f, ensure_ascii=False, indent=2)

    logger.info(f"å†³ç­–è½¨è¿¹å·²å¯¼å‡ºåˆ°: {output_file}")

# ä½¿ç”¨
export_decision_trace(miner.agent, "trace.json")
```

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•åªå¤„ç†å‡ ç¯‡è®ºæ–‡è¿›è¡Œæµ‹è¯•ï¼Ÿ

```python
# åœ¨ main_agent.py çš„ main() å‡½æ•°ä¸­
miner.run(year=2024, max_papers=3)  # åªå¤„ç†3ç¯‡
```

### Q2: å¦‚ä½•ç¦ç”¨ LLM åæ€ä»¥èŠ‚çœæˆæœ¬ï¼Ÿ

```python
miner = AgentDatasetMiner(
    enable_llm_reflection=False,  # ç¦ç”¨ LLM åæ€
    max_retries=1
)
```

### Q3: å¦‚ä½•æŸ¥çœ‹ Agent å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ

```python
# æŸ¥çœ‹é•¿æœŸè®°å¿†
agent.memory.save_to_disk()  # ä¿å­˜åˆ° memory/long_term_memory.jsonl

# è¯»å–å¹¶åˆ†æ
import json
with open("memory/long_term_memory.jsonl") as f:
    for line in f:
        record = json.loads(line)
        print(f"æ¨¡å¼: {record['pattern']}")
        print(f"ç»éªŒ: {record['experience']['reflection']['insights']}")
```

### Q4: å¦‚ä½•å¯¹æ¯”ä¸¤ä¸ªç³»ç»Ÿçš„è¾“å‡ºï¼Ÿ

```bash
# æå–æ•°æ®é›†åç§°è¿›è¡Œå¯¹æ¯”
cat outputs/dataset_neurips_results.jsonl | jq -r '.name' | sort > workflow_datasets.txt
cat outputs/dataset_agent_results.jsonl | jq -r '.name' | sort > agent_datasets.txt

# æŸ¥çœ‹å·®å¼‚
diff workflow_datasets.txt agent_datasets.txt
```

---

## ä¸‹ä¸€æ­¥

1. **è¿è¡Œå®Œæ•´å®éªŒ** (æ›´å¤šè®ºæ–‡):
   ```python
   miner.run(year=2024, max_papers=50)
   ```

2. **åˆ†æ Reflection æ•ˆæœ**:
   - ç»Ÿè®¡é‡è¯•æ¬¡æ•°
   - å¯¹æ¯”æœ‰/æ— åæ€çš„è´¨é‡å·®å¼‚
   - åˆ†æè‡ªæˆ‘ä¿®æ­£æ¡ˆä¾‹

3. **æ’°å†™è®ºæ–‡**:
   - ä½¿ç”¨ `AGENT_SYSTEM_README.md` ä½œä¸ºå‚è€ƒ
   - ä½¿ç”¨ `experiment_report.txt` ä½œä¸ºå®éªŒç»“æœ
   - é‡ç‚¹å¼ºè°ƒ Reflection åœ¨å¯æ§æ€§ä¸­çš„ä½œç”¨

---

## æŠ€æœ¯æ”¯æŒ

é‡åˆ°é—®é¢˜ï¼Ÿæ£€æŸ¥ä»¥ä¸‹å†…å®¹ï¼š

1. **æ—¥å¿—æ–‡ä»¶**: `dataset_miner_agent.log`
2. **é”™è¯¯ä¿¡æ¯**: é€šå¸¸ä¼šæœ‰è¯¦ç»†çš„ traceback
3. **LLM è°ƒç”¨**: ç¡®ä¿ API key æœ‰æ•ˆ
4. **ä¾èµ–åŒ…**: `pip install -r requirements.txt`

---

**ç¥å®éªŒé¡ºåˆ©ï¼** ğŸ‰

å¦‚æœ‰ç–‘é—®ï¼Œè¯·æŸ¥é˜… `AGENT_SYSTEM_README.md` è·å–è¯¦ç»†ä¿¡æ¯ã€‚
